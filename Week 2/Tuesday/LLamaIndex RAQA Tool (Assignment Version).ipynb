{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a more robust RAQA system using LlamaIndex\n",
    "\n",
    "We'll be putting together a system for querying both qualitative and quantitative data using LlamaIndex. \n",
    "\n",
    "To stick to a theme, we'll continue to use BarbenHeimer data as our base - but this can, and should, be extended to other topics/domains.\n",
    "\n",
    "# Build ðŸ—ï¸\n",
    "There are 3 main tasks in this notebook:\n",
    "\n",
    "- Create a Qualitative VectorStore query engine\n",
    "- Create a quantitative NLtoSQL query engine\n",
    "- Combine the two using LlamaIndex's OpenAI agent framework.\n",
    "\n",
    "# Ship ðŸš¢\n",
    "Create an host a Gradio or Chainlit application to serve your project on Hugging Face spaces.\n",
    "\n",
    "# Share ðŸš€\n",
    "Make a social media post about your final application and tag @AIMakerspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on terminology:\n",
    "\n",
    "You'll notice that there are quite a few similarities between LangChain and LlamaIndex. LlamaIndex can largely be thought of as an extension to LangChain, in some ways - but they moved some of the language around. Let's spend a few moments disambiguating the language.\n",
    "\n",
    "- `QueryEngine` -> `RetrievalQA`:\n",
    "  -  `QueryEngine` is just LlamaIndex's way of indicating something is an LLM \"chain\" on top of a retrieval system\n",
    "- `OpenAIAgent` vs. `ZeroShotAgent`:\n",
    "  - The two agents have the same fundamental pattern: Decide which of a list of tools to use to answer a user's query.\n",
    "  - `OpenAIAgent` (LlamaIndex's primary agent) does not need to rely on an agent excecutor due to the fact that it is leveraging OpenAI's [functional api](https://openai.com/blog/function-calling-and-other-api-updates) which allows the agent to interface \"directly\" with the tools instead of operating through an intermediary application process.\n",
    "\n",
    "There is, however, a much large terminological difference when it comes to discussing data.\n",
    "\n",
    "##### Nodes vs. Documents\n",
    "\n",
    "As you're aware of from the previous weeks assignments, there's an idea of `documents` in NLP which refers to text objects that exist within a corpus of documents.\n",
    "\n",
    "LlamaIndex takes this a step further and reclassifies `documents` as `nodes`. Confusingly, it refers to the `Source Document` as simply `Documents`.\n",
    "\n",
    "The `Document` -> `node` structure is, almost exactly, equivalent to the `Source Document` -> `Document` structure found in LangChain - but the new terminology comes with some clarity about different structure-indices. \n",
    "\n",
    "We won't be leveraging those structured indicies today, but we will be leveraging a \"benefit\" of the `node` structure that exists as a default in LlamaIndex, which is the ability to quickly filter nodes based on their metadata.\n",
    "\n",
    "![image](https://i.imgur.com/B1QDjs5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BOILERPLATE\n",
    "\n",
    "This is only relevant when running the code in a Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary Dependencies and Context Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies and OpenAI API key setting\n",
    "\n",
    "First of all, we'll need our primary libraries - and to set up our OpenAI API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q openai==0.27.8 llama-index==0.8.6 nltk==3.8.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")\n",
    "\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Setting\n",
    "\n",
    "Now, LlamaIndex has the ability to set `ServiceContext`. You can think of this as a config file of sorts. The basic idea here is that we use this to establish some core properties and then can pass it to various services. \n",
    "\n",
    "While we could set this up as a global context, we're going to leave it as `ServiceContext` so we can see where it's applied.\n",
    "\n",
    "We'll set a few significant contexts:\n",
    "\n",
    "- `chunk_size` - this is what it says on the tin\n",
    "- `llm` - this is where we can set what model we wish to use as our primary LLM when we're making `QueryEngine`s and more\n",
    "- `embed_model` - this will help us keep our embedding model consistent across use cases\n",
    "\n",
    "\n",
    "We'll also create some resources we're going to keep consistent across all of our indices today.\n",
    "\n",
    "- `text_splitter` - This is what we'll use to split our text, feel free to experiment here\n",
    "- `SimpleNodeParser` - This is what will work in tandem with the `text_splitter` to parse our full sized documents into nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "from llama_index import ServiceContext\n",
    "from llama_index.node_parser.simple import SimpleNodeParser\n",
    "from llama_index.langchain_helpers.text_splitter import TokenTextSplitter\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding() ### YOUR CODE HERE\n",
    "chunk_size = 1000 ### YOUR CODE HERE\n",
    "llm = OpenAI(\n",
    "    temperature=0, \n",
    "    model=\"gpt-3.5-turbo\", \n",
    "    streaming=True\n",
    ")\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm, ### YOUR CODE HERE, \n",
    "    chunk_size=chunk_size, ### YOUR CODE HERE, \n",
    "    embed_model=embed_model### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "text_splitter = TokenTextSplitter(\n",
    "    chunk_size= chunk_size ### YOUR CODE HERE\n",
    ")\n",
    "\n",
    "node_parser = SimpleNodeParser(\n",
    "    text_splitter=text_splitter### YOUR CODE HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BarbenHeimer Wikipedia Retrieval Tool\n",
    "\n",
    "Now we can get to work creating our semantic `QueryEngine`!\n",
    "\n",
    "We'll follow a similar pattern as we did with LangChain here - and the first step (as always) is to get dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q chromadb==0.4.6 tiktoken==0.4.0 sentence-transformers==2.2.2 pydantic==1.10.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q daal==2021.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex\n",
    "from llama_index.vector_stores import ChromaVectorStore\n",
    "from llama_index.storage.storage_context import StorageContext\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChromaDB\n",
    "\n",
    "We'll be using [ChromaDB](https://www.trychroma.com/) as our `VectorStore` today!\n",
    "\n",
    "It works in a similar fashion to tools like Pinecone, Weaveate, and more - but it's locally hosted and will serve our purposes fine.\n",
    "\n",
    "You'll also notice the return of `OpenAIEmbedding()`, which is the embeddings model we'll be leveraging. Of course, this is using the `ada` model under the hood - and already comes equipped with in-memory caching.\n",
    "\n",
    "You'll notice we can pass our `service_context` into our `VectorStoreIndex`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.posthog:Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "source": [
    "chroma_client = chromadb.Client()\n",
    "chroma_collection = chroma_client.create_collection(\"wikipedia_barbie_opp\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "wiki_vector_index = VectorStoreIndex([], storage_context=storage_context, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U -q wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially the same as the LangChain example - we're just going to be pulling information straight from Wikipedia using the built in `WikipediaReader`.\n",
    "\n",
    "Setting `auto_suggest=False` ensures we run into fewer auto-correct based errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.readers.wikipedia import WikipediaReader\n",
    "\n",
    "movie_list = [\"Barbie (film)\", \"Oppenheimer (film)\"]\n",
    "\n",
    "wiki_docs = WikipediaReader().load_data(pages=movie_list, auto_suggest=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Node Construction\n",
    "\n",
    "Now we will loop through our documents and metadata and construct nodes (associated with particular metadata for easy filtration later).\n",
    "\n",
    "We're using the `node_parser` we created at the top of the Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie, wiki_doc in zip(movie_list, wiki_docs):\n",
    "    nodes = node_parser.get_nodes_from_documents([wiki_doc]) ### YOUR CODE HERE\n",
    "    for node in nodes:\n",
    "        node.metadata =  {\"title\" : movie} # YOUR CODE HERE\n",
    "    wiki_vector_index.insert_nodes(nodes)### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Barbie (film)', 'Oppenheimer (film)']\n"
     ]
    }
   ],
   "source": [
    "print(movie_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auto Retriever Functional Tool\n",
    "\n",
    "This tool will leverage OpenAI's functional endpoint to select the correct metadata filter and query the filtered index - only looking at nodes with the desired metadata.\n",
    "\n",
    "A simplified diagram: ![image](https://i.imgur.com/AICDPav.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to create our `VectoreStoreInfo` object which will hold all the relevant metadata we need for each component (in this case title metadata).\n",
    "\n",
    "Notice that you need to include it in a text list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools import FunctionTool\n",
    "from llama_index.vector_stores.types import (\n",
    "    VectorStoreInfo,\n",
    "    MetadataInfo,\n",
    "    ExactMatchFilter,\n",
    "    MetadataFilters,\n",
    ")\n",
    "from llama_index.retrievers import VectorIndexRetriever\n",
    "from llama_index.query_engine import RetrieverQueryEngine\n",
    "\n",
    "from typing import List, Tuple, Any\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"semantic information about movies\",\n",
    "    metadata_info=[MetadataInfo(\n",
    "        name=\"title\",\n",
    "        type=\"str\",\n",
    "        description=\"title of the movie, one of [Barbie (film), Oppenheimer (film)]\",\n",
    "    )]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll create our base PyDantic object that we can use to ensure compatability with our application layer. This verifies that the response from the OpenAI endpoint conforms to this schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoRetrieveModel(BaseModel):\n",
    "    query: str = Field(..., description=\"natural language query string\")\n",
    "    filter_key_list: List[str] = Field(\n",
    "        ..., description=\"List of metadata filter field names\"\n",
    "    )\n",
    "    filter_value_list: List[str] = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"List of metadata filter field values (corresponding to names specified in filter_key_list)\"\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can build our function that we will use to query the functional endpoint.\n",
    "\n",
    ">The `docstring` is important to the functionality of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_retrieve_fn(\n",
    "    query: str, filter_key_list: List[str], filter_value_list: List[str]\n",
    "):\n",
    "    \"\"\"Auto retrieval function.\n",
    "\n",
    "    Performs auto-retrieval from a vector database, and then applies a set of filters.\n",
    "\n",
    "    \"\"\"\n",
    "    query = query or \"Query\"\n",
    "\n",
    "    exact_match_filters = [\n",
    "        ExactMatchFilter(key=k, value=v)\n",
    "        for k, v in zip(filter_key_list, filter_value_list)\n",
    "    ]\n",
    "    retriever = VectorIndexRetriever(\n",
    "        wiki_vector_index, filters=MetadataFilters(filters=exact_match_filters), top_k=top_k\n",
    "    )\n",
    "    query_engine = RetrieverQueryEngine.from_args(retriever)\n",
    "\n",
    "    response = query_engine.query(query)\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to wrap our system in a tool in order to integrate it into the larger application.\n",
    "\n",
    "Source Code Here:\n",
    "- [`FunctionTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/function_tool.py#L21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "description = f\"\"\"\\\n",
    "Use this tool to look up semantic information about films.\n",
    "The vector database schema is given below:\n",
    "{vector_store_info.json()}\n",
    "\"\"\"\n",
    "\n",
    "auto_retrieve_tool = FunctionTool.from_defaults(\n",
    "    fn=auto_retrieve_fn,# YOUR CODE HERE,\n",
    "    name='auto_retrieve',# YOUR CODE HERE,\n",
    "    description=description,# YOUR CODE HERE,\n",
    "    fn_schema=AutoRetrieveModel# YOUR CODE HERE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that's left to do is attach the tool to an OpenAIAgent and let it rip!\n",
    "\n",
    "Source Code Here:\n",
    "- [`OpenAIAgent`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/agent/openai_agent.py#L361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAgent\n",
    "\n",
    "agent = OpenAIAgent.from_tools(\n",
    "   [auto_retrieve_tool], ### YOUR CODE HERE\n",
    "   llm=llm,\n",
    "   verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: auto_retrieve with args: {\n",
      "  \"query\": \"Barbie movie\",\n",
      "  \"filter_key_list\": [\"title\"],\n",
      "  \"filter_value_list\": [\"Barbie (film)\"]\n",
      "}\n",
      "Got output: Barbie is a 2023 American fantasy comedy film directed by Greta Gerwig. It is the first live-action Barbie film and is based on the Barbie fashion dolls by Mattel. The film follows Barbie and Ken on a journey of self-discovery after Barbie experiences an existential crisis. The film features a supporting ensemble cast and has received critical acclaim, becoming one of the highest-grossing films of 2023.\n",
      "========================\n",
      "In the Barbie movie, Barbie and Ken go on a journey of self-discovery after Barbie experiences an existential crisis. The film is a fantasy comedy and has received critical acclaim. It is the first live-action Barbie film and is based on the Barbie fashion dolls by Mattel.\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"Tell me what happens (briefly) in the Barbie movie.\")\n",
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BarbenHeimer SQL Tool\n",
    "\n",
    "We'll walk through the steps of creating a natural language to SQL system in the following section.\n",
    "\n",
    "> NOTICE: This does not have parsing on the inputs or intermediary calls to ensure that users are using safe SQL queries. Use this with caution in a production environment without adding specific guardrails from either side of the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U sqlalchemy pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next few steps should be largely straightforward, we'll want to:\n",
    "\n",
    "1. Read in our `.csv` files into `pd.DataFrame` objects\n",
    "2. Create an in-memory `sqlite` powered `sqlalchemy` engine\n",
    "3. Cast our `pd.DataFrame` objects to the SQL engine\n",
    "4. Create an `SQLDatabase` object through LlamaIndex\n",
    "5. Use that to create a `QueryEngineTool` that we can interact with through the `NLSQLTableQueryEngine`!\n",
    "\n",
    "If you get stuck, please consult the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read `.csv` Into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "barbie_df = pd.read_csv('barbie_data/barbie.csv') # YOUR CODE HERE\n",
    "oppenheimer_df = pd.read_csv('oppenheimer_data/oppenheimer.csv') # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create SQLAlchemy engine with SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite+pysqlite:///:memory:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert `pd.DataFrame` to SQL tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "barbie_df.to_sql(\n",
    "    'barbie',# name of table\n",
    "    engine# engine\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oppenheimer_df.to_sql(\n",
    "    'oppenheimer',# name of table \n",
    "    engine# engine\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct a `SQLDatabase` index\n",
    "\n",
    "Source Code Here:\n",
    "- [`SQLDatabase`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/langchain_helpers/sql_wrapper.py#L9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import SQLDatabase\n",
    "\n",
    "sql_database = SQLDatabase(\n",
    "    engine,# YOUR CODE HERE, \n",
    "    include_tables=['barbie','oppenheimer']# YOUR CODE HERE\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the NLSQLTableQueryEngine interface for all added SQL tables\n",
    "\n",
    "Source Code Here:\n",
    "- [`NLSQLTableQueryEngine`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/indices/struct_store/sql_query.py#L75C1-L75C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.indices.struct_store.sql_query import NLSQLTableQueryEngine\n",
    "\n",
    "sql_query_engine = NLSQLTableQueryEngine(\n",
    "    sql_database=sql_database,# YOUR CODE HERE,\n",
    "    tables=['barbie','oppenheimer']# YOUR CODE HERE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrap It All Up in a `QueryEngineTool`\n",
    "\n",
    "You'll want to ensure you have a descriptive...description. \n",
    "\n",
    "An example is provided here:\n",
    "\n",
    "```\n",
    "\"Useful for translating a natural language query into a SQL query over a table containing: \"\n",
    "\"barbie, containing information related to reviews of the Barbie movie\"\n",
    "\"oppenheimer, containing information related to reviews of the Oppenheimer movie\"\n",
    "```\n",
    "\n",
    "Sorce Code Here: \n",
    "\n",
    "- [`QueryEngineTool`](https://github.com/jerryjliu/llama_index/blob/d24767b0812ac56104497d8f59095eccbe9f2b08/llama_index/tools/query_engine.py#L13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.tools.query_engine import QueryEngineTool\n",
    "\n",
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,# YOUR CODE HERE,\n",
    "    name='sqltool',# Add a name here,\n",
    "    description=(\n",
    "       'run sql tool' # Add a natural language description here\n",
    "    ),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAgent.from_tools(\n",
    "   [sql_tool], ### YOUR CODE HERE\n",
    "   llm=llm,\n",
    "   verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: sqltool with args: {\n",
      "  \"input\": \"SELECT AVG(rating) FROM films\"\n",
      "}\n",
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'barbie' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "> Table desc str: Table 'barbie' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "Got output: The average rating of the films in the Barbie category is 7.36.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is the average rating of the two films?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating of the two films is 7.36.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining The Tools Together\n",
    "\n",
    "Now, we can simple add our tools into the `OpenAIAgent`, and off we go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "barbenheimer_agent = OpenAIAgent.from_tools(\n",
    "    [auto_retrieve_tool, sql_tool],### YOUR CODE HERE\n",
    "     llm=llm,\n",
    "   verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: sqltool with args: {\n",
      "  \"input\": \"SELECT MIN(content_info.rating) AS lowest_rating, content_info.review FROM movies WHERE metadata_info.title IN ('Barbie (film)', 'Oppenheimer (film)')\"\n",
      "}\n",
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'barbie' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "> Table desc str: Table 'barbie' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: movies\n[SQL: SELECT MIN(content_info.rating) AS lowest_rating, content_info.review \nFROM movies \nWHERE metadata_info.title IN ('Barbie (film)', 'Oppenheimer (film)')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: movies",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m barbenheimer_agent\u001b[39m.\u001b[39;49mchat(\u001b[39m\"\u001b[39;49m\u001b[39mWhat is the lowest rating of the two films - and can you summarize what the reviewer said?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/callbacks/utils.py:38\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m callback_manager \u001b[39m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m callback_manager\u001b[39m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:305\u001b[0m, in \u001b[0;36mBaseOpenAIAgent.chat\u001b[0;34m(self, message, chat_history, function_call)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m@trace_method\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mchat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchat\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m     function_call: Union[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AgentChatResponse:\n\u001b[0;32m--> 305\u001b[0m     chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chat(\n\u001b[1;32m    306\u001b[0m         message, chat_history, function_call, mode\u001b[39m=\u001b[39;49mChatResponseMode\u001b[39m.\u001b[39;49mWAIT\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m chat_response\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:269\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._chat\u001b[0;34m(self, message, chat_history, function_call, mode)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_function_call, \u001b[39mdict\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_function(tools, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlatest_function_call)\n\u001b[1;32m    270\u001b[0m     n_function_calls \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    272\u001b[0m \u001b[39mreturn\u001b[39;00m agent_chat_response\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:206\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._call_function\u001b[0;34m(self, tools, function_call)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_function\u001b[39m(\u001b[39mself\u001b[39m, tools: List[BaseTool], function_call: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     function_message, tool_output \u001b[39m=\u001b[39m call_function(\n\u001b[1;32m    207\u001b[0m         tools, function_call, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_verbose\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msources\u001b[39m.\u001b[39mappend(tool_output)\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mput(function_message)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:50\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(tools, function_call, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m tool \u001b[39m=\u001b[39m get_function_by_name(tools, name)\n\u001b[1;32m     49\u001b[0m argument_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(arguments_str)\n\u001b[0;32m---> 50\u001b[0m output \u001b[39m=\u001b[39m tool(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margument_dict)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m     52\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot output: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(output)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/tools/types.py:124\u001b[0m, in \u001b[0;36mAsyncBaseTool.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/tools/query_engine.py:54\u001b[0m, in \u001b[0;36mQueryEngineTool.call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[1;32m     53\u001b[0m     query_str \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39minput\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_engine\u001b[39m.\u001b[39;49mquery(query_str)\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m ToolOutput(\n\u001b[1;32m     56\u001b[0m         content\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(response),\n\u001b[1;32m     57\u001b[0m         tool_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mname,\n\u001b[1;32m     58\u001b[0m         raw_input\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39minput\u001b[39m},\n\u001b[1;32m     59\u001b[0m         raw_output\u001b[39m=\u001b[39mresponse,\n\u001b[1;32m     60\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/indices/query/base.py:23\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     22\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 23\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(str_or_query_bundle)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/indices/struct_store/sql_query.py:280\u001b[0m, in \u001b[0;36mBaseSQLTableQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39m# assume that it's a valid SQL query\u001b[39;00m\n\u001b[1;32m    278\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m> Predicted SQL query: \u001b[39m\u001b[39m{\u001b[39;00msql_query_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m raw_response_str, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sql_database\u001b[39m.\u001b[39;49mrun_sql(sql_query_str)\n\u001b[1;32m    281\u001b[0m metadata[\u001b[39m\"\u001b[39m\u001b[39msql_query\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m sql_query_str\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_synthesize_response:\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/langchain_helpers/sql_wrapper.py:91\u001b[0m, in \u001b[0;36mSQLDatabase.run_sql\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute a SQL statement and return a string representing the results.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[39mIf the statement returns rows, a string of the results is returned.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39mIf the statement returns no rows, an empty string is returned.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mconnect() \u001b[39mas\u001b[39;00m connection:\n\u001b[0;32m---> 91\u001b[0m     cursor \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mexecute(text(command))\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m cursor\u001b[39m.\u001b[39mreturns_rows:\n\u001b[1;32m     93\u001b[0m         result \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1412\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[1;32m   1413\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1414\u001b[0m         distilled_parameters,\n\u001b[1;32m   1415\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[1;32m   1416\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    516\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1635\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1623\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1624\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1625\u001b[0m )\n\u001b[1;32m   1627\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1628\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1629\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1634\u001b[0m )\n\u001b[0;32m-> 1635\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1636\u001b[0m     dialect,\n\u001b[1;32m   1637\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1638\u001b[0m     compiled_sql,\n\u001b[1;32m   1639\u001b[0m     distilled_parameters,\n\u001b[1;32m   1640\u001b[0m     execution_options,\n\u001b[1;32m   1641\u001b[0m     compiled_sql,\n\u001b[1;32m   1642\u001b[0m     distilled_parameters,\n\u001b[1;32m   1643\u001b[0m     elem,\n\u001b[1;32m   1644\u001b[0m     extracted_params,\n\u001b[1;32m   1645\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1646\u001b[0m )\n\u001b[1;32m   1647\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1648\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1649\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1650\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         ret,\n\u001b[1;32m   1655\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1840\u001b[0m         dialect,\n\u001b[1;32m   1841\u001b[0m         context,\n\u001b[1;32m   1842\u001b[0m     )\n\u001b[1;32m   1843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[1;32m   1845\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1846\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1984\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1985\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2339\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2338\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2339\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   2340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1970\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1971\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1972\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1977\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: movies\n[SQL: SELECT MIN(content_info.rating) AS lowest_rating, content_info.review \nFROM movies \nWHERE metadata_info.title IN ('Barbie (film)', 'Oppenheimer (film)')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "response = barbenheimer_agent.chat(\"What is the lowest rating of the two films - and can you summarize what the reviewer said?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average rating of the two films is 7.36.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: sqltool with args: {\n",
      "  \"input\": \"SELECT COUNT(content_info.review) AS ken_mentions, content_info.character_summary FROM movies WHERE metadata_info.title = 'Barbie (film)' AND content_info.character_summary LIKE '%Ken%'\"\n",
      "}\n",
      "INFO:llama_index.indices.struct_store.sql_query:> Table desc str: Table 'barbie' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "> Table desc str: Table 'barbie' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n",
      "\n",
      "Table 'oppenheimer' has columns: index (BIGINT), Unnamed: 0 (BIGINT), Review_Date (TEXT), Author (TEXT), Rating (FLOAT), Review_Title (TEXT), Review (TEXT), Review_Url (TEXT), and foreign keys: .\n"
     ]
    },
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such table: movies\n[SQL: SELECT COUNT(content_info.review) AS ken_mentions, content_info.character_summary \nFROM movies \nWHERE metadata_info.title = 'Barbie (film)' \nAND content_info.character_summary LIKE '%Ken%']\n(Background on this error at: https://sqlalche.me/e/20/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such table: movies",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m barbenheimer_agent\u001b[39m.\u001b[39;49mchat(\u001b[39m\"\u001b[39;49m\u001b[39mHow many times do the Barbie reviews mention \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mKen\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m, and what is a summary of his character in the Barbie movie?\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/callbacks/utils.py:38\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m callback_manager \u001b[39m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[1;32m     37\u001b[0m \u001b[39mwith\u001b[39;00m callback_manager\u001b[39m.\u001b[39mas_trace(trace_id):\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:305\u001b[0m, in \u001b[0;36mBaseOpenAIAgent.chat\u001b[0;34m(self, message, chat_history, function_call)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39m@trace_method\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mchat\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchat\u001b[39m(\n\u001b[1;32m    300\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    303\u001b[0m     function_call: Union[\u001b[39mstr\u001b[39m, \u001b[39mdict\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    304\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m AgentChatResponse:\n\u001b[0;32m--> 305\u001b[0m     chat_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_chat(\n\u001b[1;32m    306\u001b[0m         message, chat_history, function_call, mode\u001b[39m=\u001b[39;49mChatResponseMode\u001b[39m.\u001b[39;49mWAIT\n\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[1;32m    309\u001b[0m     \u001b[39mreturn\u001b[39;00m chat_response\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:269\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._chat\u001b[0;34m(self, message, chat_history, function_call, mode)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    268\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatest_function_call, \u001b[39mdict\u001b[39m)\n\u001b[0;32m--> 269\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_function(tools, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlatest_function_call)\n\u001b[1;32m    270\u001b[0m     n_function_calls \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    272\u001b[0m \u001b[39mreturn\u001b[39;00m agent_chat_response\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:206\u001b[0m, in \u001b[0;36mBaseOpenAIAgent._call_function\u001b[0;34m(self, tools, function_call)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_call_function\u001b[39m(\u001b[39mself\u001b[39m, tools: List[BaseTool], function_call: \u001b[39mdict\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 206\u001b[0m     function_message, tool_output \u001b[39m=\u001b[39m call_function(\n\u001b[1;32m    207\u001b[0m         tools, function_call, verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_verbose\n\u001b[1;32m    208\u001b[0m     )\n\u001b[1;32m    209\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msources\u001b[39m.\u001b[39mappend(tool_output)\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory\u001b[39m.\u001b[39mput(function_message)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/agent/openai_agent.py:50\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(tools, function_call, verbose)\u001b[0m\n\u001b[1;32m     48\u001b[0m tool \u001b[39m=\u001b[39m get_function_by_name(tools, name)\n\u001b[1;32m     49\u001b[0m argument_dict \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(arguments_str)\n\u001b[0;32m---> 50\u001b[0m output \u001b[39m=\u001b[39m tool(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49margument_dict)\n\u001b[1;32m     51\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m     52\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGot output: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mstr\u001b[39m(output)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/tools/types.py:124\u001b[0m, in \u001b[0;36mAsyncBaseTool.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/tools/query_engine.py:54\u001b[0m, in \u001b[0;36mQueryEngineTool.call\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ToolOutput:\n\u001b[1;32m     53\u001b[0m     query_str \u001b[39m=\u001b[39m cast(\u001b[39mstr\u001b[39m, \u001b[39minput\u001b[39m)\n\u001b[0;32m---> 54\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query_engine\u001b[39m.\u001b[39;49mquery(query_str)\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m ToolOutput(\n\u001b[1;32m     56\u001b[0m         content\u001b[39m=\u001b[39m\u001b[39mstr\u001b[39m(response),\n\u001b[1;32m     57\u001b[0m         tool_name\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmetadata\u001b[39m.\u001b[39mname,\n\u001b[1;32m     58\u001b[0m         raw_input\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39minput\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39minput\u001b[39m},\n\u001b[1;32m     59\u001b[0m         raw_output\u001b[39m=\u001b[39mresponse,\n\u001b[1;32m     60\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/indices/query/base.py:23\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[0;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(str_or_query_bundle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m     22\u001b[0m     str_or_query_bundle \u001b[39m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[0;32m---> 23\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(str_or_query_bundle)\n\u001b[1;32m     24\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/indices/struct_store/sql_query.py:280\u001b[0m, in \u001b[0;36mBaseSQLTableQueryEngine._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[39m# assume that it's a valid SQL query\u001b[39;00m\n\u001b[1;32m    278\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m> Predicted SQL query: \u001b[39m\u001b[39m{\u001b[39;00msql_query_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m raw_response_str, metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sql_database\u001b[39m.\u001b[39;49mrun_sql(sql_query_str)\n\u001b[1;32m    281\u001b[0m metadata[\u001b[39m\"\u001b[39m\u001b[39msql_query\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m sql_query_str\n\u001b[1;32m    283\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_synthesize_response:\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/llama_index/langchain_helpers/sql_wrapper.py:91\u001b[0m, in \u001b[0;36mSQLDatabase.run_sql\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Execute a SQL statement and return a string representing the results.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[39mIf the statement returns rows, a string of the results is returned.\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[39mIf the statement returns no rows, an empty string is returned.\u001b[39;00m\n\u001b[1;32m     89\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mconnect() \u001b[39mas\u001b[39;00m connection:\n\u001b[0;32m---> 91\u001b[0m     cursor \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49mexecute(text(command))\n\u001b[1;32m     92\u001b[0m     \u001b[39mif\u001b[39;00m cursor\u001b[39m.\u001b[39mreturns_rows:\n\u001b[1;32m     93\u001b[0m         result \u001b[39m=\u001b[39m cursor\u001b[39m.\u001b[39mfetchall()\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1412\u001b[0m, in \u001b[0;36mConnection.execute\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1410\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(statement) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   1411\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m     \u001b[39mreturn\u001b[39;00m meth(\n\u001b[1;32m   1413\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1414\u001b[0m         distilled_parameters,\n\u001b[1;32m   1415\u001b[0m         execution_options \u001b[39mor\u001b[39;49;00m NO_OPTIONS,\n\u001b[1;32m   1416\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:515\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, distilled_params, execution_options)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[39mif\u001b[39;00m TYPE_CHECKING:\n\u001b[1;32m    514\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, Executable)\n\u001b[0;32m--> 515\u001b[0m     \u001b[39mreturn\u001b[39;00m connection\u001b[39m.\u001b[39;49m_execute_clauseelement(\n\u001b[1;32m    516\u001b[0m         \u001b[39mself\u001b[39;49m, distilled_params, execution_options\n\u001b[1;32m    517\u001b[0m     )\n\u001b[1;32m    518\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    519\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mObjectNotExecutableError(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1635\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, distilled_parameters, execution_options)\u001b[0m\n\u001b[1;32m   1623\u001b[0m compiled_cache: Optional[CompiledCacheType] \u001b[39m=\u001b[39m execution_options\u001b[39m.\u001b[39mget(\n\u001b[1;32m   1624\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcompiled_cache\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_compiled_cache\n\u001b[1;32m   1625\u001b[0m )\n\u001b[1;32m   1627\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[39m=\u001b[39m elem\u001b[39m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1628\u001b[0m     dialect\u001b[39m=\u001b[39mdialect,\n\u001b[1;32m   1629\u001b[0m     compiled_cache\u001b[39m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m     linting\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdialect\u001b[39m.\u001b[39mcompiler_linting \u001b[39m|\u001b[39m compiler\u001b[39m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1634\u001b[0m )\n\u001b[0;32m-> 1635\u001b[0m ret \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_context(\n\u001b[1;32m   1636\u001b[0m     dialect,\n\u001b[1;32m   1637\u001b[0m     dialect\u001b[39m.\u001b[39;49mexecution_ctx_cls\u001b[39m.\u001b[39;49m_init_compiled,\n\u001b[1;32m   1638\u001b[0m     compiled_sql,\n\u001b[1;32m   1639\u001b[0m     distilled_parameters,\n\u001b[1;32m   1640\u001b[0m     execution_options,\n\u001b[1;32m   1641\u001b[0m     compiled_sql,\n\u001b[1;32m   1642\u001b[0m     distilled_parameters,\n\u001b[1;32m   1643\u001b[0m     elem,\n\u001b[1;32m   1644\u001b[0m     extracted_params,\n\u001b[1;32m   1645\u001b[0m     cache_hit\u001b[39m=\u001b[39;49mcache_hit,\n\u001b[1;32m   1646\u001b[0m )\n\u001b[1;32m   1647\u001b[0m \u001b[39mif\u001b[39;00m has_events:\n\u001b[1;32m   1648\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_execute(\n\u001b[1;32m   1649\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1650\u001b[0m         elem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         ret,\n\u001b[1;32m   1655\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1844\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1839\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exec_insertmany_context(\n\u001b[1;32m   1840\u001b[0m         dialect,\n\u001b[1;32m   1841\u001b[0m         context,\n\u001b[1;32m   1842\u001b[0m     )\n\u001b[1;32m   1843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1844\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exec_single_context(\n\u001b[1;32m   1845\u001b[0m         dialect, context, statement, parameters\n\u001b[1;32m   1846\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1984\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1981\u001b[0m     result \u001b[39m=\u001b[39m context\u001b[39m.\u001b[39m_setup_result_proxy()\n\u001b[1;32m   1983\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m-> 1984\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_dbapi_exception(\n\u001b[1;32m   1985\u001b[0m         e, str_statement, effective_parameters, cursor, context\n\u001b[1;32m   1986\u001b[0m     )\n\u001b[1;32m   1988\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2339\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context, is_sub_exec)\u001b[0m\n\u001b[1;32m   2337\u001b[0m \u001b[39melif\u001b[39;00m should_wrap:\n\u001b[1;32m   2338\u001b[0m     \u001b[39massert\u001b[39;00m sqlalchemy_exception \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 2339\u001b[0m     \u001b[39mraise\u001b[39;00m sqlalchemy_exception\u001b[39m.\u001b[39mwith_traceback(exc_info[\u001b[39m2\u001b[39m]) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m   2340\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2341\u001b[0m     \u001b[39massert\u001b[39;00m exc_info[\u001b[39m1\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1965\u001b[0m, in \u001b[0;36mConnection._exec_single_context\u001b[0;34m(self, dialect, context, statement, parameters)\u001b[0m\n\u001b[1;32m   1963\u001b[0m                 \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m   1964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1965\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdialect\u001b[39m.\u001b[39;49mdo_execute(\n\u001b[1;32m   1966\u001b[0m             cursor, str_statement, effective_parameters, context\n\u001b[1;32m   1967\u001b[0m         )\n\u001b[1;32m   1969\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_events \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine\u001b[39m.\u001b[39m_has_events:\n\u001b[1;32m   1970\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mafter_cursor_execute(\n\u001b[1;32m   1971\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m   1972\u001b[0m         cursor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1976\u001b[0m         context\u001b[39m.\u001b[39mexecutemany,\n\u001b[1;32m   1977\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/llmops-course/lib/python3.11/site-packages/sqlalchemy/engine/default.py:921\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdo_execute\u001b[39m(\u001b[39mself\u001b[39m, cursor, statement, parameters, context\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 921\u001b[0m     cursor\u001b[39m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such table: movies\n[SQL: SELECT COUNT(content_info.review) AS ken_mentions, content_info.character_summary \nFROM movies \nWHERE metadata_info.title = 'Barbie (film)' \nAND content_info.character_summary LIKE '%Ken%']\n(Background on this error at: https://sqlalche.me/e/20/e3q8)"
     ]
    }
   ],
   "source": [
    "response = barbenheimer_agent.chat(\"How many times do the Barbie reviews mention 'Ken', and what is a summary of his character in the Barbie movie?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
